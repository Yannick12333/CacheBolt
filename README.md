# ‚ö°Ô∏è CacheBolt

> A blazing-fast reverse proxy with intelligent caching and multi-backend object storage support.

---

## üöÄ Introduction

**CacheBolt** is a high-performance reverse proxy designed to cache and serve responses with minimal latency. It intelligently stores responses in memory and synchronizes them with persistent object storage backends.

This tool is ideal for accelerating APIs, file delivery, and improving reliability under high load.

CacheBolt reads its configuration from a YAML file. By default, it expects a file named:

```bash
./config.yaml
```

You can override this path via CLI:

```bash
./cachebolt --config ./path/to/custom.yaml
```
---

### ‚ú® Features

- üîÅ Reverse HTTP proxy powered by [Axum](https://github.com/tokio-rs/axum) and [Tokio](https://tokio.rs/)
- üöÄ Fast, concurrent in-memory caching with LRU eviction
- ‚òÅÔ∏è Multi-cloud object store support:
  - üü¢ Amazon S3
  - üîµ Google Cloud Storage
  - üî∂ Azure Blob Storage
  - üíΩ Local filesystem
- üìâ Memory-based cache eviction (threshold-configurable)
- ‚è±Ô∏è Latency-based failover policies (regex route rules)
- üß† Smart fallback if upstreams are slow or unavailable

---
## üîÅ Request Flow (Text Diagram)

```text
Client sends GET request
        |
        v
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            proxy_handler receives request              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        |
        v
Check if URI is marked as degraded (should_failover)
        |
        ‚îú‚îÄ‚îÄ Yes --> try_cache(key)
        ‚îÇ            ‚îú‚îÄ‚îÄ Hit in memory? 
        ‚îÇ            ‚îÇ     ‚îî‚îÄ‚îÄ ‚úÖ Serve from memory
        ‚îÇ            ‚îú‚îÄ‚îÄ Else: Hit in storage?
        ‚îÇ            ‚îÇ     ‚îî‚îÄ‚îÄ ‚úÖ Load from selected storage backend (GCS, S3, Azure, or Local)
        ‚îÇ            ‚îÇ            ‚îî‚îÄ‚îÄ Load into memory + Serve
        ‚îÇ            ‚îî‚îÄ‚îÄ Else: ‚ùå Return 502 (no cache, no backend)
        ‚îÇ
        ‚îî‚îÄ‚îÄ No
             |
             v
      Check MEMORY_CACHE for key
             |
             ‚îú‚îÄ‚îÄ Hit --> ‚úÖ Serve from memory
             ‚îî‚îÄ‚îÄ Miss
                  |
                  v
         Acquire semaphore (concurrency guard)
                  |
                  ‚îú‚îÄ‚îÄ Denied --> Check memory again
                  ‚îÇ               ‚îú‚îÄ‚îÄ Hit --> ‚úÖ Serve
                  ‚îÇ               ‚îî‚îÄ‚îÄ ‚ùå Return 502 (overloaded)
                  |
                  ‚îî‚îÄ‚îÄ Acquired --> forward_request to backend
                                   |
                                   ‚îú‚îÄ‚îÄ Response latency > threshold?
                                   ‚îÇ         ‚îî‚îÄ‚îÄ Yes --> mark_latency_fail
                                   |
                                   ‚îú‚îÄ‚îÄ Downstream OK?
                                   ‚îÇ         |
                                   ‚îÇ         ‚îú‚îÄ‚îÄ Build CachedResponse
                                   ‚îÇ         ‚îú‚îÄ‚îÄ In failover mode?
                                   ‚îÇ         ‚îÇ     ‚îú‚îÄ‚îÄ Yes --> Skip caching
                                   ‚îÇ         ‚îÇ     ‚îî‚îÄ‚îÄ No:
                                   ‚îÇ         ‚îÇ           ‚îú‚îÄ‚îÄ Put in MEMORY_CACHE
                                   ‚îÇ         ‚îÇ           ‚îî‚îÄ‚îÄ Send to CACHE_WRITER (persist to backend)
                                   ‚îÇ         ‚îî‚îÄ‚îÄ ‚úÖ Return response
                                   |
                                   ‚îî‚îÄ‚îÄ Downstream failed --> try_cache fallback
```


---
## üîß Configuration

The config is written in YAML. Example:

```yaml
app_id: my-service

max_concurrent_requests: 200
downstream_base_url: http://localhost:4000
downstream_timeout_secs: 5

storage_backend: s3  # options: gcs, s3, azure, local
gcs_bucket: cachebolt
s3_bucket: my-cachebolt-bucket
azure_container: cachebolt-container

memory_eviction:
  threshold_percent: 90

latency_failover:
  default_max_latency_ms: 300
  path_rules:
    - pattern: "^/api/v1/products/.*"
      max_latency_ms: 150
    - pattern: "^/auth/.*"
      max_latency_ms: 100
```

---

## üîê Cloud Storage Authentication

Depending on the storage backend, you'll need to configure credentials via environment variables:

### Google Cloud Storage (GCS)
- Must be authenticated using Application Default Credentials (ADC), which you can set via:
```bash
export GOOGLE_APPLICATION_CREDENTIALS="/path/to/service-account.json"
```

### Amazon S3
- Required environment variables:
```bash
export AWS_ACCESS_KEY_ID=your-access-key-id
export AWS_SECRET_ACCESS_KEY=your-secret-key
export AWS_REGION=us-east-1  # or your specific region
```

### Azure Blob Storage
- Required environment variables:
```bash
export AZURE_STORAGE_ACCOUNT=your_account_name
export AZURE_STORAGE_ACCESS_KEY=your_access_key
```

### Local Filesystem
- No additional credentials required. Cache files will be saved locally.

---

## ‚ñ∂Ô∏è Running the Binary

Default mode:
```bash
./cachebolt
```

Custom config path:
```bash
./cachebolt --config ./config/prod.yaml
```

Docker:
```bash
docker run --rm -p 3000:3000 \
  -v $(pwd)/config:/config \
  -v $(pwd)/cache:/data \
  -e GOOGLE_APPLICATION_CREDENTIALS=/config/adc.json \
  ghcr.io/<your-org>/cachebolt:latest \
  --config /config/config.yaml
```

---

## üì¶ Building

To build locally:
```bash
cargo build --release
```

To cross-compile:
See `.github/workflows/release.yml` for cross-target examples.

---

## üìÑ License

Licensed under the [Apache License 2.0](./LICENSE).
